# proof-GPT
WIP

A 774M GPT-2 model pre-trained on mathematical data.
